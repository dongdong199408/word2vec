{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Embedding, Lambda, LSTM, Dense,concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# 每隔1000个epoch，学习率减小为原来的1/10\n",
    "def scheduler(epoch):\n",
    "    if epoch % 1000 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "\n",
    "# reduce_lr = LearningRateScheduler(scheduler)\n",
    "def stopwordslist():  # 设置停用词\n",
    "    stopwords = []\n",
    "    if not os.path.exists('./stopwords.txt'):\n",
    "        print('未发现停用词表！')\n",
    "    else:\n",
    "        stopwords = [line.strip() for line in open('stopwords.txt', encoding='UTF-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "\n",
    "def getdata(fname):\n",
    "    f = open(fname, 'r', encoding='UTF-8')\n",
    "    lines = f.readlines()\n",
    "    sentences = []\n",
    "    data = []\n",
    "    stopwords = stopwordslist()\n",
    "    for line in lines:\n",
    "        data.append(line.strip())  # 原始句子\n",
    "        sts = list(jieba.cut(line.strip(), cut_all=False))  # 分词后\n",
    "        splits = []  # 去停用词后\n",
    "        for w in sts:\n",
    "            if w not in stopwords:\n",
    "                splits.append(w)\n",
    "        sentences.append(splits)\n",
    "    f.close()\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def bulid_dic(sentences):  # 建立各种字典\n",
    "    words = {}  # 词频表\n",
    "    nb_sentence = 0  # 总句子数\n",
    "    total = 0.  # 总词频\n",
    "\n",
    "    for d in sentences:\n",
    "        nb_sentence += 1\n",
    "        for w in d:\n",
    "            if w not in words:\n",
    "                words[w] = 0\n",
    "            words[w] += 1\n",
    "            total += 1\n",
    "        if nb_sentence % 100 == 0:\n",
    "            print(u'已经找到%s个句子' % nb_sentence)\n",
    "\n",
    "    words = {i: j for i, j in words.items() if j >= min_count}  # 截断词频\n",
    "    id2word = {i + 1: j for i, j in enumerate(words)}  # id到词语的映射，0表示UNK\n",
    "    id2word.update({0:'UNK'})\n",
    "    word2id = {j: i for i, j in id2word.items()}  # 词语到id的映射\n",
    "    nb_word = len(words) + 1  # 总词数（算上填充符号0）\n",
    "\n",
    "    subsamples = {i: j / total for i, j in words.items() if j / total > subsample_t}\n",
    "    subsamples = {i: subsample_t / j + (subsample_t / j) ** 0.5 for i, j in\n",
    "                  subsamples.items()}  # 这个降采样公式，是按照word2vec的源码来的\n",
    "    subsamples = {word2id[i]: j for i, j in subsamples.items() if j < 1.}  # 降采样表\n",
    "    return nb_sentence, id2word, word2id, nb_word, subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.693 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已经找到100个句子\n",
      "已经找到200个句子\n",
      "已经找到300个句子\n",
      "已经找到400个句子\n",
      "已经找到500个句子\n",
      "已经找到600个句子\n",
      "已经找到700个句子\n",
      "已经找到800个句子\n",
      "已经找到900个句子\n",
      "已经找到1000个句子\n",
      "已经找到1100个句子\n",
      "已经找到1200个句子\n",
      "已经找到1300个句子\n",
      "已经找到1400个句子\n",
      "已经找到1500个句子\n",
      "已经找到1600个句子\n",
      "已经找到1700个句子\n",
      "已经找到1800个句子\n",
      "已经找到1900个句子\n",
      "已经找到2000个句子\n",
      "已经找到2100个句子\n",
      "已经找到2200个句子\n",
      "已经找到2300个句子\n",
      "已经找到2400个句子\n",
      "已经找到2500个句子\n",
      "已经找到2600个句子\n",
      "已经找到2700个句子\n",
      "已经找到2800个句子\n",
      "已经找到2900个句子\n",
      "已经找到3000个句子\n",
      "已经找到3100个句子\n",
      "已经找到3200个句子\n",
      "已经找到3300个句子\n",
      "已经找到3400个句子\n",
      "已经找到3500个句子\n",
      "已经找到3600个句子\n",
      "已经找到3700个句子\n",
      "已经找到3800个句子\n",
      "已经找到3900个句子\n",
      "已经找到4000个句子\n",
      "已经找到4100个句子\n",
      "已经找到4200个句子\n",
      "已经找到4300个句子\n",
      "已经找到4400个句子\n",
      "已经找到4500个句子\n",
      "已经找到4600个句子\n",
      "已经找到4700个句子\n",
      "已经找到4800个句子\n",
      "已经找到4900个句子\n",
      "已经找到5000个句子\n",
      "已经找到5100个句子\n",
      "已经找到5200个句子\n",
      "已经找到5300个句子\n",
      "已经找到5400个句子\n",
      "已经找到5500个句子\n",
      "已经找到5600个句子\n",
      "已经找到5700个句子\n",
      "已经找到5800个句子\n",
      "已经找到5900个句子\n",
      "已经找到6000个句子\n",
      "已经找到6100个句子\n",
      "已经找到6200个句子\n",
      "已经找到6300个句子\n",
      "已经找到6400个句子\n",
      "已经找到6500个句子\n",
      "已经找到6600个句子\n",
      "已经找到6700个句子\n",
      "已经找到6800个句子\n",
      "已经找到6900个句子\n",
      "已经找到7000个句子\n",
      "已经找到7100个句子\n",
      "已经找到7200个句子\n",
      "已经找到7300个句子\n",
      "已经找到7400个句子\n",
      "已经找到7500个句子\n",
      "已经找到7600个句子\n",
      "已经找到7700个句子\n",
      "已经找到7800个句子\n",
      "已经找到7900个句子\n",
      "已经找到8000个句子\n",
      "已经找到8100个句子\n",
      "已经找到8200个句子\n",
      "已经找到8300个句子\n",
      "已经找到8400个句子\n",
      "已经找到8500个句子\n",
      "已经找到8600个句子\n",
      "已经找到8700个句子\n",
      "已经找到8800个句子\n",
      "已经找到8900个句子\n",
      "已经找到9000个句子\n",
      "已经找到9100个句子\n",
      "已经找到9200个句子\n",
      "已经找到9300个句子\n",
      "已经找到9400个句子\n",
      "已经找到9500个句子\n",
      "已经找到9600个句子\n",
      "已经找到9700个句子\n",
      "已经找到9800个句子\n",
      "已经找到9900个句子\n",
      "已经找到10000个句子\n",
      "已经找到10100个句子\n",
      "已经找到10200个句子\n",
      "已经找到10300个句子\n",
      "已经找到10400个句子\n",
      "已经找到10500个句子\n",
      "已经找到10600个句子\n",
      "已经找到10700个句子\n",
      "已经找到10800个句子\n",
      "已经找到10900个句子\n",
      "已经找到11000个句子\n",
      "已经找到11100个句子\n",
      "已经找到11200个句子\n",
      "已经找到11300个句子\n",
      "已经找到11400个句子\n",
      "已经找到11500个句子\n",
      "已经找到11600个句子\n",
      "已经找到11700个句子\n",
      "已经找到11800个句子\n",
      "已经找到11900个句子\n",
      "已经找到12000个句子\n",
      "已经找到12100个句子\n",
      "已经找到12200个句子\n",
      "已经找到12300个句子\n",
      "已经找到12400个句子\n",
      "已经找到12500个句子\n",
      "已经找到12600个句子\n",
      "已经找到12700个句子\n",
      "已经找到12800个句子\n",
      "已经找到12900个句子\n",
      "已经找到13000个句子\n",
      "已经找到13100个句子\n",
      "已经找到13200个句子\n",
      "已经找到13300个句子\n",
      "已经找到13400个句子\n",
      "已经找到13500个句子\n",
      "已经找到13600个句子\n",
      "已经找到13700个句子\n",
      "已经找到13800个句子\n",
      "已经找到13900个句子\n",
      "已经找到14000个句子\n",
      "已经找到14100个句子\n",
      "已经找到14200个句子\n",
      "已经找到14300个句子\n",
      "已经找到14400个句子\n",
      "已经找到14500个句子\n",
      "已经找到14600个句子\n",
      "已经找到14700个句子\n",
      "已经找到14800个句子\n",
      "已经找到14900个句子\n",
      "已经找到15000个句子\n",
      "已经找到15100个句子\n",
      "已经找到15200个句子\n",
      "已经找到15300个句子\n",
      "已经找到15400个句子\n",
      "已经找到15500个句子\n",
      "已经找到15600个句子\n",
      "已经找到15700个句子\n",
      "已经找到15800个句子\n",
      "已经找到15900个句子\n",
      "已经找到16000个句子\n",
      "已经找到16100个句子\n",
      "已经找到16200个句子\n",
      "已经找到16300个句子\n",
      "已经找到16400个句子\n",
      "已经找到16500个句子\n",
      "已经找到16600个句子\n",
      "已经找到16700个句子\n",
      "已经找到16800个句子\n",
      "已经找到16900个句子\n",
      "已经找到17000个句子\n",
      "已经找到17100个句子\n",
      "已经找到17200个句子\n",
      "已经找到17300个句子\n",
      "已经找到17400个句子\n",
      "已经找到17500个句子\n",
      "已经找到17600个句子\n",
      "已经找到17700个句子\n",
      "已经找到17800个句子\n",
      "已经找到17900个句子\n",
      "已经找到18000个句子\n",
      "已经找到18100个句子\n",
      "已经找到18200个句子\n",
      "已经找到18300个句子\n",
      "已经找到18400个句子\n",
      "已经找到18500个句子\n",
      "已经找到18600个句子\n",
      "已经找到18700个句子\n",
      "已经找到18800个句子\n",
      "已经找到18900个句子\n",
      "已经找到19000个句子\n",
      "已经找到19100个句子\n",
      "已经找到19200个句子\n",
      "已经找到19300个句子\n",
      "已经找到19400个句子\n",
      "已经找到19500个句子\n",
      "已经找到19600个句子\n",
      "已经找到19700个句子\n",
      "已经找到19800个句子\n",
      "已经找到19900个句子\n",
      "已经找到20000个句子\n",
      "已经找到20100个句子\n",
      "已经找到20200个句子\n",
      "已经找到20300个句子\n",
      "已经找到20400个句子\n",
      "已经找到20500个句子\n",
      "已经找到20600个句子\n",
      "已经找到20700个句子\n",
      "已经找到20800个句子\n",
      "已经找到20900个句子\n",
      "已经找到21000个句子\n",
      "已经找到21100个句子\n",
      "已经找到21200个句子\n",
      "已经找到21300个句子\n",
      "已经找到21400个句子\n",
      "已经找到21500个句子\n",
      "已经找到21600个句子\n",
      "已经找到21700个句子\n",
      "已经找到21800个句子\n",
      "已经找到21900个句子\n",
      "已经找到22000个句子\n",
      "已经找到22100个句子\n",
      "已经找到22200个句子\n",
      "已经找到22300个句子\n",
      "已经找到22400个句子\n",
      "已经找到22500个句子\n",
      "已经找到22600个句子\n",
      "已经找到22700个句子\n",
      "已经找到22800个句子\n",
      "已经找到22900个句子\n",
      "已经找到23000个句子\n",
      "已经找到23100个句子\n",
      "已经找到23200个句子\n",
      "已经找到23300个句子\n",
      "已经找到23400个句子\n",
      "已经找到23500个句子\n",
      "已经找到23600个句子\n",
      "已经找到23700个句子\n",
      "已经找到23800个句子\n",
      "已经找到23900个句子\n",
      "已经找到24000个句子\n",
      "已经找到24100个句子\n",
      "已经找到24200个句子\n",
      "已经找到24300个句子\n",
      "已经找到24400个句子\n",
      "已经找到24500个句子\n",
      "已经找到24600个句子\n",
      "已经找到24700个句子\n",
      "已经找到24800个句子\n",
      "已经找到24900个句子\n",
      "已经找到25000个句子\n",
      "已经找到25100个句子\n",
      "已经找到25200个句子\n",
      "已经找到25300个句子\n",
      "已经找到25400个句子\n",
      "已经找到25500个句子\n",
      "已经找到25600个句子\n",
      "已经找到25700个句子\n",
      "已经找到25800个句子\n",
      "已经找到25900个句子\n",
      "已经找到26000个句子\n",
      "已经找到26100个句子\n",
      "已经找到26200个句子\n",
      "已经找到26300个句子\n",
      "已经找到26400个句子\n",
      "已经找到26500个句子\n",
      "已经找到26600个句子\n",
      "已经找到26700个句子\n",
      "已经找到26800个句子\n",
      "已经找到26900个句子\n",
      "已经找到27000个句子\n",
      "已经找到27100个句子\n",
      "已经找到27200个句子\n",
      "已经找到27300个句子\n",
      "已经找到27400个句子\n",
      "已经找到27500个句子\n",
      "已经找到27600个句子\n",
      "已经找到27700个句子\n",
      "已经找到27800个句子\n",
      "已经找到27900个句子\n",
      "已经找到28000个句子\n",
      "已经找到28100个句子\n",
      "已经找到28200个句子\n",
      "已经找到28300个句子\n",
      "已经找到28400个句子\n",
      "已经找到28500个句子\n",
      "已经找到28600个句子\n",
      "已经找到28700个句子\n",
      "已经找到28800个句子\n",
      "已经找到28900个句子\n",
      "已经找到29000个句子\n",
      "已经找到29100个句子\n",
      "已经找到29200个句子\n",
      "已经找到29300个句子\n",
      "已经找到29400个句子\n",
      "已经找到29500个句子\n",
      "已经找到29600个句子\n",
      "已经找到29700个句子\n",
      "已经找到29800个句子\n",
      "已经找到29900个句子\n",
      "已经找到30000个句子\n",
      "已经找到30100个句子\n",
      "已经找到30200个句子\n",
      "已经找到30300个句子\n",
      "已经找到30400个句子\n",
      "已经找到30500个句子\n",
      "已经找到30600个句子\n",
      "已经找到30700个句子\n",
      "已经找到30800个句子\n",
      "已经找到30900个句子\n",
      "已经找到31000个句子\n",
      "已经找到31100个句子\n",
      "已经找到31200个句子\n",
      "已经找到31300个句子\n",
      "已经找到31400个句子\n",
      "已经找到31500个句子\n",
      "已经找到31600个句子\n",
      "已经找到31700个句子\n",
      "已经找到31800个句子\n",
      "已经找到31900个句子\n",
      "已经找到32000个句子\n",
      "已经找到32100个句子\n",
      "已经找到32200个句子\n",
      "已经找到32300个句子\n",
      "已经找到32400个句子\n",
      "已经找到32500个句子\n",
      "已经找到32600个句子\n",
      "已经找到32700个句子\n",
      "已经找到32800个句子\n",
      "已经找到32900个句子\n",
      "已经找到33000个句子\n",
      "已经找到33100个句子\n",
      "已经找到33200个句子\n",
      "已经找到33300个句子\n",
      "已经找到33400个句子\n",
      "已经找到33500个句子\n",
      "已经找到33600个句子\n",
      "已经找到33700个句子\n",
      "已经找到33800个句子\n",
      "已经找到33900个句子\n",
      "已经找到34000个句子\n",
      "已经找到34100个句子\n",
      "已经找到34200个句子\n",
      "已经找到34300个句子\n",
      "已经找到34400个句子\n",
      "已经找到34500个句子\n",
      "已经找到34600个句子\n",
      "已经找到34700个句子\n",
      "已经找到34800个句子\n",
      "已经找到34900个句子\n",
      "已经找到35000个句子\n",
      "已经找到35100个句子\n",
      "已经找到35200个句子\n",
      "已经找到35300个句子\n",
      "已经找到35400个句子\n",
      "已经找到35500个句子\n",
      "已经找到35600个句子\n",
      "已经找到35700个句子\n",
      "已经找到35800个句子\n",
      "已经找到35900个句子\n",
      "已经找到36000个句子\n",
      "已经找到36100个句子\n",
      "已经找到36200个句子\n",
      "已经找到36300个句子\n",
      "已经找到36400个句子\n",
      "已经找到36500个句子\n",
      "已经找到36600个句子\n",
      "已经找到36700个句子\n",
      "已经找到36800个句子\n",
      "已经找到36900个句子\n",
      "已经找到37000个句子\n",
      "已经找到37100个句子\n",
      "已经找到37200个句子\n",
      "已经找到37300个句子\n",
      "已经找到37400个句子\n",
      "已经找到37500个句子\n",
      "已经找到37600个句子\n",
      "已经找到37700个句子\n",
      "已经找到37800个句子\n",
      "已经找到37900个句子\n",
      "已经找到38000个句子\n",
      "已经找到38100个句子\n",
      "已经找到38200个句子\n",
      "已经找到38300个句子\n",
      "已经找到38400个句子\n",
      "已经找到38500个句子\n",
      "已经找到38600个句子\n",
      "已经找到38700个句子\n",
      "已经找到38800个句子\n",
      "已经找到38900个句子\n",
      "已经找到39000个句子\n",
      "已经找到39100个句子\n",
      "已经找到39200个句子\n",
      "已经找到39300个句子\n",
      "已经找到39400个句子\n",
      "已经找到39500个句子\n",
      "已经找到39600个句子\n",
      "已经找到39700个句子\n",
      "已经找到39800个句子\n",
      "已经找到39900个句子\n",
      "已经找到40000个句子\n",
      "已经找到40100个句子\n",
      "已经找到40200个句子\n",
      "已经找到40300个句子\n",
      "已经找到40400个句子\n",
      "已经找到40500个句子\n",
      "已经找到40600个句子\n",
      "已经找到40700个句子\n",
      "已经找到40800个句子\n",
      "已经找到40900个句子\n",
      "已经找到41000个句子\n",
      "已经找到41100个句子\n",
      "已经找到41200个句子\n",
      "已经找到41300个句子\n",
      "已经找到41400个句子\n",
      "已经找到41500个句子\n",
      "已经找到41600个句子\n",
      "已经找到41700个句子\n",
      "已经找到41800个句子\n",
      "已经找到41900个句子\n",
      "已经找到42000个句子\n",
      "已经找到42100个句子\n",
      "已经找到42200个句子\n",
      "已经找到42300个句子\n",
      "已经找到42400个句子\n",
      "已经找到42500个句子\n",
      "已经找到42600个句子\n",
      "已经找到42700个句子\n",
      "已经找到42800个句子\n",
      "已经找到42900个句子\n",
      "已经找到43000个句子\n",
      "已经找到43100个句子\n",
      "已经找到43200个句子\n",
      "已经找到43300个句子\n",
      "已经找到43400个句子\n",
      "已经找到43500个句子\n",
      "已经找到43600个句子\n",
      "已经找到43700个句子\n",
      "已经找到43800个句子\n",
      "已经找到43900个句子\n",
      "已经找到44000个句子\n",
      "已经找到44100个句子\n",
      "已经找到44200个句子\n",
      "已经找到44300个句子\n",
      "已经找到44400个句子\n",
      "已经找到44500个句子\n",
      "已经找到44600个句子\n",
      "已经找到44700个句子\n",
      "已经找到44800个句子\n",
      "已经找到44900个句子\n",
      "已经找到45000个句子\n",
      "已经找到45100个句子\n",
      "已经找到45200个句子\n",
      "已经找到45300个句子\n",
      "已经找到45400个句子\n",
      "已经找到45500个句子\n",
      "已经找到45600个句子\n",
      "已经找到45700个句子\n",
      "已经找到45800个句子\n",
      "已经找到45900个句子\n",
      "已经找到46000个句子\n",
      "已经找到46100个句子\n",
      "已经找到46200个句子\n",
      "已经找到46300个句子\n",
      "已经找到46400个句子\n",
      "已经找到46500个句子\n",
      "已经找到46600个句子\n",
      "已经找到46700个句子\n",
      "已经找到46800个句子\n",
      "已经找到46900个句子\n",
      "已经找到47000个句子\n",
      "已经找到47100个句子\n",
      "已经找到47200个句子\n",
      "已经找到47300个句子\n",
      "已经找到47400个句子\n",
      "已经找到47500个句子\n",
      "已经找到47600个句子\n",
      "已经找到47700个句子\n",
      "已经找到47800个句子\n",
      "已经找到47900个句子\n",
      "已经找到48000个句子\n",
      "已经找到48100个句子\n",
      "已经找到48200个句子\n",
      "已经找到48300个句子\n",
      "已经找到48400个句子\n",
      "已经找到48500个句子\n",
      "已经找到48600个句子\n",
      "已经找到48700个句子\n",
      "已经找到48800个句子\n",
      "已经找到48900个句子\n",
      "已经找到49000个句子\n",
      "已经找到49100个句子\n",
      "已经找到49200个句子\n",
      "已经找到49300个句子\n",
      "已经找到49400个句子\n",
      "已经找到49500个句子\n",
      "已经找到49600个句子\n",
      "已经找到49700个句子\n",
      "已经找到49800个句子\n",
      "已经找到49900个句子\n",
      "已经找到50000个句子\n",
      "已经找到50100个句子\n",
      "已经找到50200个句子\n",
      "已经找到50300个句子\n",
      "已经找到50400个句子\n",
      "已经找到50500个句子\n",
      "已经找到50600个句子\n",
      "已经找到50700个句子\n",
      "已经找到50800个句子\n",
      "已经找到50900个句子\n",
      "已经找到51000个句子\n",
      "已经找到51100个句子\n",
      "已经找到51200个句子\n",
      "已经找到51300个句子\n",
      "已经找到51400个句子\n",
      "已经找到51500个句子\n",
      "已经找到51600个句子\n",
      "已经找到51700个句子\n",
      "已经找到51800个句子\n",
      "已经找到51900个句子\n",
      "已经找到52000个句子\n",
      "已经找到52100个句子\n",
      "已经找到52200个句子\n",
      "已经找到52300个句子\n",
      "已经找到52400个句子\n",
      "已经找到52500个句子\n",
      "已经找到52600个句子\n",
      "已经找到52700个句子\n",
      "已经找到52800个句子\n",
      "已经找到52900个句子\n",
      "已经找到53000个句子\n",
      "已经找到53100个句子\n",
      "已经找到53200个句子\n",
      "已经找到53300个句子\n",
      "已经找到53400个句子\n",
      "已经找到53500个句子\n",
      "已经找到53600个句子\n",
      "已经找到53700个句子\n",
      "已经找到53800个句子\n",
      "已经找到53900个句子\n",
      "已经找到54000个句子\n",
      "已经找到54100个句子\n",
      "已经找到54200个句子\n",
      "已经找到54300个句子\n",
      "已经找到54400个句子\n",
      "已经找到54500个句子\n",
      "已经找到54600个句子\n",
      "已经找到54700个句子\n",
      "已经找到54800个句子\n",
      "已经找到54900个句子\n",
      "已经找到55000个句子\n",
      "已经找到55100个句子\n",
      "已经找到55200个句子\n",
      "已经找到55300个句子\n",
      "已经找到55400个句子\n",
      "已经找到55500个句子\n",
      "已经找到55600个句子\n",
      "已经找到55700个句子\n",
      "已经找到55800个句子\n",
      "已经找到55900个句子\n",
      "已经找到56000个句子\n",
      "已经找到56100个句子\n",
      "已经找到56200个句子\n",
      "已经找到56300个句子\n",
      "已经找到56400个句子\n",
      "已经找到56500个句子\n",
      "已经找到56600个句子\n",
      "已经找到56700个句子\n",
      "已经找到56800个句子\n",
      "已经找到56900个句子\n",
      "已经找到57000个句子\n",
      "已经找到57100个句子\n",
      "已经找到57200个句子\n",
      "已经找到57300个句子\n",
      "已经找到57400个句子\n",
      "已经找到57500个句子\n",
      "已经找到57600个句子\n",
      "已经找到57700个句子\n",
      "已经找到57800个句子\n",
      "已经找到57900个句子\n",
      "已经找到58000个句子\n",
      "已经找到58100个句子\n",
      "已经找到58200个句子\n",
      "已经找到58300个句子\n",
      "已经找到58400个句子\n",
      "已经找到58500个句子\n",
      "已经找到58600个句子\n",
      "已经找到58700个句子\n",
      "已经找到58800个句子\n",
      "已经找到58900个句子\n",
      "已经找到59000个句子\n",
      "已经找到59100个句子\n",
      "已经找到59200个句子\n",
      "已经找到59300个句子\n",
      "已经找到59400个句子\n",
      "已经找到59500个句子\n",
      "已经找到59600个句子\n",
      "已经找到59700个句子\n",
      "已经找到59800个句子\n",
      "已经找到59900个句子\n",
      "已经找到60000个句子\n",
      "已经找到60100个句子\n",
      "已经找到60200个句子\n",
      "已经找到60300个句子\n",
      "已经找到60400个句子\n",
      "已经找到60500个句子\n",
      "已经找到60600个句子\n",
      "已经找到60700个句子\n",
      "已经找到60800个句子\n",
      "已经找到60900个句子\n",
      "已经找到61000个句子\n",
      "已经找到61100个句子\n",
      "已经找到61200个句子\n",
      "已经找到61300个句子\n",
      "已经找到61400个句子\n",
      "已经找到61500个句子\n",
      "已经找到61600个句子\n",
      "已经找到61700个句子\n",
      "已经找到61800个句子\n",
      "已经找到61900个句子\n",
      "已经找到62000个句子\n",
      "已经找到62100个句子\n",
      "已经找到62200个句子\n",
      "已经找到62300个句子\n",
      "已经找到62400个句子\n",
      "已经找到62500个句子\n",
      "已经找到62600个句子\n",
      "已经找到62700个句子\n",
      "已经找到62800个句子\n",
      "已经找到62900个句子\n",
      "已经找到63000个句子\n",
      "已经找到63100个句子\n",
      "已经找到63200个句子\n",
      "已经找到63300个句子\n",
      "已经找到63400个句子\n",
      "已经找到63500个句子\n",
      "已经找到63600个句子\n",
      "已经找到63700个句子\n",
      "已经找到63800个句子\n",
      "已经找到63900个句子\n",
      "已经找到64000个句子\n",
      "已经找到64100个句子\n",
      "已经找到64200个句子\n",
      "已经找到64300个句子\n",
      "已经找到64400个句子\n",
      "已经找到64500个句子\n",
      "已经找到64600个句子\n",
      "已经找到64700个句子\n",
      "已经找到64800个句子\n",
      "已经找到64900个句子\n",
      "已经找到65000个句子\n",
      "已经找到65100个句子\n",
      "已经找到65200个句子\n",
      "已经找到65300个句子\n",
      "已经找到65400个句子\n",
      "已经找到65500个句子\n",
      "已经找到65600个句子\n",
      "已经找到65700个句子\n",
      "已经找到65800个句子\n",
      "已经找到65900个句子\n",
      "已经找到66000个句子\n",
      "已经找到66100个句子\n",
      "已经找到66200个句子\n",
      "已经找到66300个句子\n",
      "已经找到66400个句子\n",
      "已经找到66500个句子\n",
      "已经找到66600个句子\n",
      "已经找到66700个句子\n",
      "已经找到66800个句子\n",
      "已经找到66900个句子\n",
      "已经找到67000个句子\n",
      "已经找到67100个句子\n",
      "已经找到67200个句子\n",
      "已经找到67300个句子\n",
      "已经找到67400个句子\n",
      "已经找到67500个句子\n",
      "已经找到67600个句子\n",
      "已经找到67700个句子\n",
      "已经找到67800个句子\n",
      "已经找到67900个句子\n",
      "已经找到68000个句子\n",
      "已经找到68100个句子\n",
      "已经找到68200个句子\n"
     ]
    }
   ],
   "source": [
    "fname = './result/chatrobot_messageresult_sentence.txt'  # 数据集(语料库) 一个文档\n",
    "log_filepath = './tmp/keras_log'\n",
    "word_size = 200  # 词向量维度\n",
    "window = 5  # 窗口大小\n",
    "nb_negative = 150  # 随机负采样的样本数\n",
    "min_count = 0  # 频数少于min_count的词将会被抛弃\n",
    "nb_worker = 4  # 读取数据的并发数\n",
    "nb_epoch = 2  # 迭代次数，由于使用了adam，迭代次数1～2次效果就相当不错\n",
    "subsample_t = 1e-5  # 词频大于subsample_t的词语，会被降采样，这是提高速度和词向量质量的有效方案\n",
    "nb_sentence_per_batch = 40\n",
    "# 目前是以句子为单位作为batch，多少个句子作为一个batch（这样才容易估计训练过程中的steps参数，另外注意，样本数是正比于字数的。）\n",
    "\n",
    "sentences = getdata(fname)  # 读原始数据\n",
    "nb_sentence, id2word, word2id, nb_word, subsamples = bulid_dic(sentences)  # 建字典\n",
    "# 构造训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(word2id, subsamples, data):  # 训练数据生成器\n",
    "    batch= 0\n",
    "    x0, y0 = [], []\n",
    "    for d in data:\n",
    "        d = [0] * window + [word2id[w] for w in d if w in word2id] + [0] * window\n",
    "        r = np.random.random(len(d))\n",
    "        for i in range(window, len(d) - window):\n",
    "            if d[i] in subsamples and r[i] > subsamples[d[i]]:  # 满足降采样条件的直接跳过\n",
    "                continue\n",
    "            x0.append(d[i - window:i] + d[i + 1:i + 1 + window])\n",
    "            y0.append([d[i]])\n",
    "        batch+= 1\n",
    "        if batch%nb_sentence_per_batch==0:\n",
    "            #把\n",
    "            x, y = np.array(x0), np.array(y0)\n",
    "            z = np.zeros((len(x), 1))\n",
    "            c=np.random.randint(0,5,size=(len(x), 1),dtype='int32')\n",
    "            x0=[];y0=[]\n",
    "            yield ([x, y], [z,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "def single_generator(word2id, subsamples, data):  # 训练数据生成器\n",
    "    for d in data:\n",
    "        d = [0] * window + [word2id[w] for w in d if w in word2id] + [0] * window\n",
    "        r = np.random.random(len(d))\n",
    "        for i in range(window, len(d) - window):\n",
    "            if d[i] in subsamples and r[i] > subsamples[d[i]]:  # 满足降采样条件的直接跳过\n",
    "                continue\n",
    "            x0=d[i - window:i] + d[i + 1:i + 1 + window]\n",
    "            y0=[d[i]]\n",
    "            x, y = np.array(x0), np.array(y0)\n",
    "            yield x, y\n",
    "\n",
    "class CaptchaSequence(Sequence):\n",
    "    def __init__(self, batch_size, steps,n_class=5):\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = steps\n",
    "        self.n_class = n_class\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        generator = next(single_generator(word2id, subsamples, sentences))\n",
    "        X = np.zeros((self.batch_size,2*window), dtype=np.float32)\n",
    "        y = np.zeros((self.batch_size, 1), dtype=np.uint8)\n",
    "        z = np.zeros((self.batch_size, 1), dtype=np.uint8)\n",
    "        c=np.random.randint(0,self.n_class,size=(self.batch_size, 1),dtype='int32')\n",
    "        for i in range(self.batch_size):\n",
    "            X[i] = generator[0]\n",
    "            y[i] = generator[1]\n",
    "        return ([X, y],[z,c])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_w2vm(word_size, window, nb_word, nb_negative):\n",
    "    K.clear_session()  # 清除之前的模型，省得压满内存\n",
    "    # CBOW输入\n",
    "    target_word = Input(shape=(1,), dtype='int32',name='target_input')\n",
    "    input_words = Input(shape=(window * 2,), dtype='int32', name='main_input')\n",
    "    #首先定义一个分类的模型\n",
    "\n",
    "    #input_length: 输入序列的长度，当它是固定的时。 如果你需要连接 Flatten 和 Dense 层，则这个参数是必须的 （没有它，dense 层的输出尺寸就无法计算）。\n",
    "    input_vecs = Embedding(nb_word, word_size, name='word2vec_main')(input_words)\n",
    "    class_input_vecs = Embedding(nb_word, word_size, name='word2vec_target')(target_word)\n",
    "    # 自定义一个lstm层\n",
    "    lstm_out = LSTM(32)(class_input_vecs)\n",
    "    dense_out = Dense(64, activation='relu')(lstm_out)\n",
    "    # 增加一个全连接\n",
    "    class_output = Dense(5, activation='sigmoid', name='class_out')(dense_out)\n",
    "    #全面函数层用lambda定义\n",
    "    input_vecs_sum = Lambda(lambda x: K.sum(x, axis=1))(input_vecs)  # CBOW模型，直接将上下文词向量求和,也可去平均\n",
    "    # 构造随机负样本，与目标组成抽样\n",
    "\n",
    "    target_input=concatenate([input_vecs_sum ,class_output],name='concat_class')\n",
    "\n",
    "    #生成均匀分布负样本，从16个样本中，一个正样本找到答案，应该打乱顺序的找\n",
    "    negatives = Lambda(lambda x: K.random_uniform((K.shape(x)[0], nb_negative), 0, nb_word, 'int32'),name='target_negatives')(target_word)\n",
    "    samples = Lambda(lambda x: K.concatenate(x,axis=-1),name='target_samples')([target_word, negatives])  # 构造抽样，负样本随机抽。负样本也可能抽到正样本，但概率小。\n",
    "    # 只在抽样内做Dense和softmax\n",
    "    #相当于添加权重曾\n",
    "    softmax_weights = Embedding(nb_word, word_size+5, name='W')(samples)\n",
    "    softmax_biases = Embedding(nb_word, 1, name='b')(samples)\n",
    "    #相当于sampled_softmax_loss\n",
    "    softmax = Lambda(lambda x:\n",
    "                     K.softmax((K.batch_dot(x[0], K.expand_dims(x[1], 2)) + x[2])[:, :, 0])\n",
    "                     ,name='main_out')([softmax_weights, target_input, softmax_biases])  # 用Embedding层存参数，用K后端实现矩阵乘法，以此复现Dense层的功能\n",
    "    #留意到，我们构造抽样时，把目标放在了第一位，也就是说，softmax的目标id总是0，这可以从data_generator中的z变量的写法可以看出\n",
    "\n",
    "    model = Model(inputs=[input_words, target_word], outputs=[softmax,class_output])\n",
    "    model.compile(loss={'main_out':'sparse_categorical_crossentropy', 'class_out':'sparse_categorical_crossentropy'},\n",
    "                  loss_weights={'main_out': 1, 'class_out': 0.5},\n",
    "                        optimizer='adam', metrics=['accuracy'])\n",
    "    '''\n",
    "    如果你的 targets 是 one-hot 编码，用 categorical_crossentropy\n",
    "　　one-hot 编码：[0, 0, 1], [1, 0, 0], [0, 1, 0]\n",
    "    如果你的 tagets 是 数字编码 ，用 sparse_categorical_crossentropy\n",
    "　　数字编码：2, 0, 1\n",
    "    '''\n",
    "    # 请留意用的是sparse_categorical_crossentropy而不是categorical_crossentropy\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1707/1707 [==============================] - 34s 20ms/step - loss: 1.6720 - main_out_loss: 0.8684 - class_out_loss: 1.6072 - main_out_acc: 0.8495 - class_out_acc: 0.2167 - val_loss: 1.3128 - val_main_out_loss: 0.5071 - val_class_out_loss: 1.6114 - val_main_out_acc: 0.9153 - val_class_out_acc: 0.2017\n",
      "Epoch 2/2\n",
      "1707/1707 [==============================] - 33s 19ms/step - loss: 1.1460 - main_out_loss: 0.3419 - class_out_loss: 1.6082 - main_out_acc: 0.9645 - class_out_acc: 0.2040 - val_loss: 1.1003 - val_main_out_loss: 0.2940 - val_class_out_loss: 1.6125 - val_main_out_acc: 0.9657 - val_class_out_acc: 0.2008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f849797cf60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造训练数据\n",
    "model = build_w2vm(word_size, window, nb_word, nb_negative)  # 搭模型\n",
    "tb_cb = keras.callbacks.TensorBoard(log_dir=log_filepath, write_images=1, histogram_freq=1)\n",
    "# 设置log的存储位置，将网络权值以图片格式保持在tensorboard中显示，设置每一个周期计算一次网络的权值，每层输出值的分布直方图\n",
    "reduce_lr = LearningRateScheduler(scheduler)\n",
    "\n",
    "'''\n",
    "第二种学习率下降\n",
    "monitor：被监测的量\n",
    "factor：每次减少学习率的因子，学习率将以lr = lr*factor的形式被减少\n",
    "patience：当patience个epoch过去而模型性能不提升时，学习率减少的动作会被触发\n",
    "mode：‘auto’，‘min’，‘max’之一，在min模式下，如果检测值触发学习率减少。在max模式下，当检测值不再上升则触发学习率减少。\n",
    "epsilon：阈值，用来确定是否进入检测值的“平原区”\n",
    "cooldown：学习率减少后，会经过cooldown个epoch才重新进行正常操作\n",
    "min_lr：学习率的下限\n",
    "'''\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.0001, mode='auto')\n",
    "cbks = [reduce_lr]\n",
    "train_data = CaptchaSequence(batch_size=nb_sentence_per_batch, steps=nb_sentence)\n",
    "valid_data = CaptchaSequence(batch_size=nb_sentence_per_batch, steps=nb_sentence//10) \n",
    "model.fit_generator(train_data,\n",
    "          validation_data=valid_data,\n",
    "          steps_per_epoch=int(nb_sentence / nb_sentence_per_batch),\n",
    "          epochs=nb_epoch,\n",
    "          validation_steps=nb_sentence//10,\n",
    "          callbacks = cbks,\n",
    "          workers=nb_worker,\n",
    "          use_multiprocessing=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved!\n"
     ]
    }
   ],
   "source": [
    "#保存model\n",
    "#保存embedding文件\n",
    "def save_embedding(final_embeddings, model_path, reverse_dictionary):\n",
    "    f = open(model_path,'w+')\n",
    "    for index, item in enumerate(final_embeddings):\n",
    "        f.write(reverse_dictionary[index] + '\\t' + ','.join([str(vec) for vec in item]) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "model.save('./model/word2vec.h5')\n",
    "print('model saved!')\n",
    "model = load_model('./model/word2vec.h5')\n",
    "plot_model(model, to_file='model.png')\n",
    "embeddings = model.get_weights()[0]\n",
    "save_embedding(embeddings,'./model/keras_cbow_wordvec.bin',id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
